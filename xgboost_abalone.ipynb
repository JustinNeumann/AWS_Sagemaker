{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with Amazon SageMaker XGBoost algorithm\n",
    "_**Single machine training for regression with Amazon SageMaker XGBoost algorithm**_\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "## Contents\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Setup](#Setup)\n",
    "  1. [Fetching the dataset](#Fetching-the-dataset)\n",
    "  2. [Data Ingestion](#Data-ingestion)\n",
    "3. [Training the XGBoost model](#Training-the-XGBoost-model)\n",
    "  1. [Plotting evaluation metrics](#Plotting-evaluation-metrics)\n",
    "4. [Set up hosting for the model](#Set-up-hosting-for-the-model)\n",
    "  1. [Import model into hosting](#Import-model-into-hosting)\n",
    "  2. [Create endpoint configuration](#Create-endpoint-configuration)\n",
    "  3. [Create endpoint](#Create-endpoint)\n",
    "5. [Validate the model for use](#Validate-the-model-for-use)\n",
    "\n",
    "---\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates the use of Amazon SageMakerâ€™s implementation of the XGBoost algorithm to train and host a regression model. We use the [Abalone data](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html) originally from the [UCI data repository](https://archive.ics.uci.edu/ml/datasets/abalone). More details about the original dataset can be found [here](https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.names).  In the libsvm converted [version](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html), the nominal feature (Male/Female/Infant) has been converted into a real valued feature. Age of abalone is to be predicted from eight physical measurements.  \n",
    "\n",
    "---\n",
    "## Setup\n",
    "\n",
    "\n",
    "This notebook was created and tested on an ml.m4.4xlarge notebook instance.\n",
    "\n",
    "Let's start by specifying:\n",
    "1. The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "1. The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 67.6 ms, sys: 3.27 ms, total: 70.8 ms\n",
      "Wall time: 444 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(region, 'xgboost')\n",
    "\n",
    "bucket='sagemaker-cert-bucket' # put your s3 bucket name here, and create s3 bucket\n",
    "prefix = 'sagemaker/xgboost-regression-abalone'\n",
    "# customize to your bucket where you have stored the data\n",
    "bucket_path = 'https://s3-{}.amazonaws.com/{}'.format(region,bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the dataset\n",
    "\n",
    "Following methods split the data into train/test/validation datasets and upload files to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.6 ms, sys: 2.51 ms, total: 27.1 ms\n",
      "Wall time: 103 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# download the dataset from S3\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "BUCKET_NAME = 'sagemaker-cert-bucket' # replace with your bucket name\n",
    "KEY = 'abalone/abalone.csv' # replace with your object key\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "try:\n",
    "    s3.Bucket(BUCKET_NAME).download_file(KEY, 'abalone.csv')\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == \"404\":\n",
    "        print(\"The object does not exist.\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Data loaded into dataframe.\n",
      "CPU times: user 3.89 ms, sys: 3.51 ms, total: 7.41 ms\n",
      "Wall time: 6.72 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "try:\n",
    "  model_data = pd.read_csv('abalone.csv',index_col=0)\n",
    "  print('Success: Data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2923, 8) (1254, 8)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data))])\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('train.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('test.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/test.csv')).upload_file('test.csv')\n",
    "s3_input_test = sagemaker.s3_input(s3_data='s3://{}/{}/validation'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the XGBoost model\n",
    "\n",
    "After setting training parameters, we kick off training, and poll for status until training is completed, which in this example, takes between 5 and 6 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "xgb = sagemaker.estimator.Estimator(container, role, train_instance_count=1, train_instance_type='ml.m4.xlarge',output_path='s3://{}/{}/output'.format(bucket, prefix),sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(max_depth=5,eta=0.2,gamma=4,min_child_weight=6,subsample=0.8,silent=0,objective='reg:linear',num_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: xgboost-2019-04-13-10-04-43-369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-13 10:04:43 Starting - Starting the training job...\n",
      "2019-04-13 10:04:56 Starting - Launching requested ML instances......\n",
      "2019-04-13 10:06:01 Starting - Preparing the instances for training.........\n",
      "2019-04-13 10:07:42 Downloading - Downloading input data\n",
      "2019-04-13 10:07:42 Training - Downloading the training image.\n",
      "\u001b[31mArguments: train\u001b[0m\n",
      "\u001b[31m[2019-04-13:10:07:47:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[31m[2019-04-13:10:07:47:INFO] Path /opt/ml/input/data/validation does not exist!\u001b[0m\n",
      "\u001b[31m[2019-04-13:10:07:47:INFO] File size need to be processed in the node: 0.14mb. Available memory size in the node: 8403.56mb\u001b[0m\n",
      "\u001b[31m[2019-04-13:10:07:47:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[10:07:47] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[31m[10:07:47] 2923x7 matrix with 20461 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 46 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[0]#011train-rmse:0.106715\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 44 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[1]#011train-rmse:0.090584\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 48 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[2]#011train-rmse:0.080885\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 40 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[3]#011train-rmse:0.072269\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 42 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[4]#011train-rmse:0.065428\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 44 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[5]#011train-rmse:0.059554\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[6]#011train-rmse:0.059469\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[7]#011train-rmse:0.059396\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[8]#011train-rmse:0.059357\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[9]#011train-rmse:0.059329\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[10]#011train-rmse:0.059307\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[11]#011train-rmse:0.059289\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[12]#011train-rmse:0.059283\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[13]#011train-rmse:0.059277\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[14]#011train-rmse:0.059274\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[15]#011train-rmse:0.059273\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[16]#011train-rmse:0.059271\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[17]#011train-rmse:0.05927\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[18]#011train-rmse:0.05927\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[19]#011train-rmse:0.059269\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[20]#011train-rmse:0.059268\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 46 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[21]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 46 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[22]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[23]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[24]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[25]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[26]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[27]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[28]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[29]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[30]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[31]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[32]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[33]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[34]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 34 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[35]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[36]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 46 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[37]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[38]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[39]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[40]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[41]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[42]#011train-rmse:0.059267\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[43]#011train-rmse:0.059267\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[44]#011train-rmse:0.059267\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[45]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[46]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[47]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[48]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[49]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[50]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[51]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[52]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[53]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[54]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[55]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[56]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[57]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[58]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[59]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[60]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[61]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 46 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[62]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[63]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[64]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 46 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[65]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[66]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[67]#011train-rmse:0.059267\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 46 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[68]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[69]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 46 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[70]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[71]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 34 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[72]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[73]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[74]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[75]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 46 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[76]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[77]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[78]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[79]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[80]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 34 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[81]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[82]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[83]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[84]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[85]#011train-rmse:0.059266\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[86]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[87]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[88]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 34 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[89]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[90]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 34 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[91]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[92]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 34 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[93]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[94]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[95]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[96]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[97]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[98]#011train-rmse:0.059265\u001b[0m\n",
      "\u001b[31m[10:07:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[99]#011train-rmse:0.059265\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-04-13 10:07:56 Uploading - Uploading generated training model\n",
      "2019-04-13 10:07:56 Completed - Training job completed\n",
      "Billable seconds: 42\n"
     ]
    }
   ],
   "source": [
    "xgb.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the \"validation\" channel has been initialized too. The SageMaker XGBoost algorithm actually calculates RMSE and writes it to the CloudWatch logs on the data passed to the \"validation\" channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting evaluation metrics\n",
    "Evaluation metrics for the completed training job are available in CloudWatch. We can pull the area under curve metric for the validation data set and plot it to see the performance of the model over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sagemaker.analytics import TrainingJobAnalytics\n",
    "\n",
    "metric_name = 'validation:rmse'\n",
    "\n",
    "metrics_dataframe = TrainingJobAnalytics(training_job_name=job_name, metric_names=[metric_name]).dataframe()\n",
    "plt = metrics_dataframe.plot(kind='line', figsize=(12,5), x='timestamp', y='value', style='b.', legend=False)\n",
    "plt.set_ylabel(metric_name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up hosting for the model\n",
    "In order to set up hosting, we have to import the model from training to hosting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: xgboost-2019-04-13-10-09-05-173\n",
      "INFO:sagemaker:Creating endpoint with name xgboost-2019-04-13-10-04-43-369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model for use\n",
    "Finally, the customer can now validate the model for use. They can obtain the endpoint from the client library using the result from previous operations, and generate classifications from the trained model using that endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1254,)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "test_data_array = test_data.drop([\"Rings\"], axis=1).as_matrix() #load the data into an array\n",
    "xgb_predictor.content_type = 'text/csv' # set the data type for an inference\n",
    "xgb_predictor.serializer = csv_serializer # set the serializer type\n",
    "predictions = xgb_predictor.predict(test_data_array).decode('utf-8') # predict!\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3977102 , 0.5685336 , 0.5685336 , ..., 0.54675025, 0.54675025,\n",
       "       0.5685336 ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Endpoint\n",
    "Once you are done using the endpoint, you can use the following to delete it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: xgboost-2019-04-13-10-04-43-369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': '128D653EF1D5C983',\n",
       "   'HostId': 'qdgr4vcTd4UyNlUsiKGLlbvC1JeZCN68C0q6RV1vUbdIrJ7zCqxgyQf2zxKMbtHXK553zG9vVGQ=',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': 'qdgr4vcTd4UyNlUsiKGLlbvC1JeZCN68C0q6RV1vUbdIrJ7zCqxgyQf2zxKMbtHXK553zG9vVGQ=',\n",
       "    'x-amz-request-id': '128D653EF1D5C983',\n",
       "    'date': 'Sat, 13 Apr 2019 10:18:34 GMT',\n",
       "    'connection': 'close',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'sagemaker/xgboost-regression-abalone/train/train.csv'},\n",
       "   {'Key': 'sagemaker/xgboost-regression-abalone/validation/test.csv'},\n",
       "   {'Key': 'sagemaker/xgboost-regression-abalone/output/xgboost-2019-04-13-10-04-43-369/output/model.tar.gz'},\n",
       "   {'Key': 'loan/loan.csv'},\n",
       "   {'Key': 'loan/'},\n",
       "   {'Key': 'sagemaker/xgboost-regression-abalone/single-xgboost/xgboost-regression-abalone-2019-04-13-09-46-59/output/model.tar.gz'},\n",
       "   {'Key': 'abalone/abalone.csv'},\n",
       "   {'Key': 'abalone/'}]}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket)\n",
    "#bucket_to_delete.objects.all().delete()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
